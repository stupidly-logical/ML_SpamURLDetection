{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this analysis, we explored some important features that have proved to be sound and effective in predicting phishing/malicious websites based on lexical characteristics of URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import re\n",
    "import matplotlib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os.path import splitext\n",
    "import ipaddress as ip\n",
    "import tldextract\n",
    "import whois\n",
    "import datetime\n",
    "from urllib.parse import urlparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL</th>\n",
       "      <th>Lable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://www.cuveecoffee.com/</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://tcbsolutions.net/</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://www-groups.dcs.st-and.ac.uk/~history/In...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://www.npr.org/rss/rss.php?id=1006</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://www.chihuahuainvita.com/65/wp-content/a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 URL  Lable\n",
       "0                        http://www.cuveecoffee.com/      0\n",
       "1                           http://tcbsolutions.net/      0\n",
       "2  http://www-groups.dcs.st-and.ac.uk/~history/In...      0\n",
       "3             http://www.npr.org/rss/rss.php?id=1006      0\n",
       "4  http://www.chihuahuainvita.com/65/wp-content/a...      1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./dataset.csv\")\n",
    "#df=df.sample(frac=1)\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7030"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df) #displaying 5 records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2016's top most suspicious TLD and words\n",
    "Suspicious_TLD=['zip','cricket','link','work','party','gq','kim','country','science','tk']\n",
    "Suspicious_Domain=['luckytime.co.kr','mattfoll.eu.interia.pl','trafficholder.com','dl.baixaki.com.br','bembed.redtube.comr','tags.expo9.exponential.com','deepspacer.com','funad.co.kr','trafficconverter.biz']\n",
    "#trend micro's top malicious domains "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hackers can use long URL to hide the doubtful part in the address bar. For example: \n",
    "http://federmacedoadv.com.br/3f/aze/ab51e2e319e51502f416dbe46b773a5e/?cmd=_home&amp;dispatch=11004d58f5b74f8dc1e7c2e8dd4105e811004d58f5b74f8dc1e7c2e8dd4105e8@phishing.website.html\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method to count number of dots\n",
    "def countdots(url):  \n",
    "    return url.count('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method to count number of delimeters\n",
    "def countdelim(url):\n",
    "    count = 0\n",
    "    delim=[';','_','?','=','&']\n",
    "    for each in url:\n",
    "        if each in delim:\n",
    "            count = count + 1\n",
    "    \n",
    "    return count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If an IP address is used as an alternative of the domain name in the URL, such as “http://125.98.3.123/fake.html”, users can be sure that someone is trying to steal their personal information. Sometimes, the IP address is even transformed into hexadecimal code as shown in the following link “http://0x58.0xCC.0xCA.0x62/2/paypal.ca/index.html”. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Is IP addr present as th hostname, let's validate\n",
    "\n",
    "import ipaddress as ip #works only in python 3\n",
    "\n",
    "def isip(uri):\n",
    "    try:\n",
    "        if ip.ip_address(uri):\n",
    "            return 1\n",
    "    except:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#method to check the presence of hyphens\n",
    "\n",
    "def isPresentHyphen(url):\n",
    "    return url.count('-')\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using “@” symbol in the URL leads the browser to ignore everything preceding the “@” symbol and the real address often follows the “@” symbol. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#method to check the presence of @\n",
    "\n",
    "def isPresentAt(url):\n",
    "    return url.count('@')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The existence of “//” within the URL path means that the user will be redirected to another website. An example of such URL’s is: “http://www.legitimate.com//http://www.phishing.com”. We examine the presence of “//”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isPresentDSlash(url):\n",
    "    return url.count('//')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def countSubDir(url):\n",
    "    return url.count('/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ext(url):\n",
    "    \"\"\"Return the filename extension from url, or ''.\"\"\"\n",
    "    \n",
    "    root, ext = splitext(url)\n",
    "    return ext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def countSubDomain(subdomain):\n",
    "    if not subdomain:\n",
    "        return 0\n",
    "    else:\n",
    "        return len(subdomain.split('.'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def countQueries(query):\n",
    "    if not query:\n",
    "        return 0\n",
    "    else:\n",
    "        return len(query.split('&'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "featureSet = pd.DataFrame(columns=('url','no of dots','presence of hyphen','len of url','presence of at',\\\n",
    "'presence of double slash','no of subdir','no of subdomain','len of domain','no of queries','is IP','presence of Suspicious_TLD',\\\n",
    "'presence of suspicious domain','create_age(months)','expiry_age(months)','update_age(days)','country','file extension','label'))'''\n",
    "\n",
    "featureSet = pd.DataFrame(columns=('url','no of dots','presence of hyphen','len of url','presence of at',\\\n",
    "'presence of double slash','no of subdir','no of subdomain','len of domain','no of queries','is IP','presence of Suspicious_TLD',\\\n",
    "'presence of suspicious domain','label'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.parse import urlparse\n",
    "import tldextract\n",
    "def getFeatures(url, label): \n",
    "    result = []\n",
    "    url = str(url)\n",
    "    \n",
    "    #add the url to feature set\n",
    "    result.append(url)\n",
    "    \n",
    "    #parse the URL and extract the domain information\n",
    "    path = urlparse(url)\n",
    "    ext = tldextract.extract(url)\n",
    "    \n",
    "    #counting number of dots in subdomain    \n",
    "    result.append(countdots(ext.subdomain))\n",
    "    \n",
    "    #checking hyphen in domain   \n",
    "    result.append(isPresentHyphen(path.netloc))\n",
    "    \n",
    "    #length of URL    \n",
    "    result.append(len(url))\n",
    "    \n",
    "    #checking @ in the url    \n",
    "    result.append(isPresentAt(path.netloc))\n",
    "    \n",
    "    #checking presence of double slash    \n",
    "    result.append(isPresentDSlash(path.path))\n",
    "    \n",
    "    #Count number of subdir    \n",
    "    result.append(countSubDir(path.path))\n",
    "    \n",
    "    #number of sub domain    \n",
    "    result.append(countSubDomain(ext.subdomain))\n",
    "    \n",
    "    #length of domain name    \n",
    "    result.append(len(path.netloc))\n",
    "    \n",
    "    #count number of queries    \n",
    "    result.append(len(path.query))\n",
    "    \n",
    "    #Adding domain information\n",
    "    \n",
    "    #if IP address is being used as a URL     \n",
    "    result.append(isip(ext.domain))\n",
    "    \n",
    "    #presence of Suspicious_TLD\n",
    "    result.append(1 if ext.suffix in Suspicious_TLD else 0)\n",
    "    \n",
    "    #presence of suspicious domain\n",
    "    result.append(1 if '.'.join(ext[1:]) in Suspicious_Domain else 0 )\n",
    "     \n",
    "    '''\n",
    "      \n",
    "    #Get domain information by asking whois\n",
    "    domain = '.'.join(ext[1:])\n",
    "    w = whois.whois(domain)\n",
    "    \n",
    "    avg_month_time=365.2425/12.0\n",
    "    \n",
    "                  \n",
    "    #calculate creation age in months\n",
    "                  \n",
    "    if w.creation_date == None or type(w.creation_date) is str :\n",
    "        result.append(-1)\n",
    "        #training_df['create_age(months)'] = -1\n",
    "    else:\n",
    "        if(type(w.creation_date) is list): \n",
    "            create_date=w.creation_date[-1]\n",
    "        else:\n",
    "            create_date=w.creation_date\n",
    "\n",
    "        if(type(create_date) is datetime.datetime):\n",
    "            today_date=datetime.datetime.now()\n",
    "            create_age_in_mon=((today_date - create_date).days)/avg_month_time\n",
    "            create_age_in_mon=round(create_age_in_mon)\n",
    "            result.append(create_age_in_mon)\n",
    "            #training_df['create_age(months)'] = create_age_in_mon\n",
    "            \n",
    "        else:\n",
    "            result.append(-1)\n",
    "            #training_df['create_age(months)'] = -1\n",
    "    \n",
    "    #calculate expiry age in months\n",
    "                  \n",
    "    if(w.expiration_date==None or type(w.expiration_date) is str):\n",
    "        #training_df['expiry_age(months)'] = -1\n",
    "        result.append(-1)\n",
    "    else:\n",
    "        if(type(w.expiration_date) is list):\n",
    "            expiry_date=w.expiration_date[-1]\n",
    "        else:\n",
    "            expiry_date=w.expiration_date\n",
    "        if(type(expiry_date) is datetime.datetime):\n",
    "            today_date=datetime.datetime.now()\n",
    "            expiry_age_in_mon=((expiry_date - today_date).days)/avg_month_time\n",
    "            expiry_age_in_mon=round(expiry_age_in_mon)\n",
    "            #training_df['expiry_age(months)'] = expiry_age_in_mon\n",
    "            #### appending  in months Appended to the Vector\n",
    "            result.append(expiry_age_in_mon)\n",
    "        else:\n",
    "            #training_df['expiry_age(months)'] = -1\n",
    "            result.append(-1)#### expiry date error so append -1\n",
    "\n",
    "    #find the age of last update\n",
    "                  \n",
    "    if(w.updated_date==None or type(w.updated_date) is str):\n",
    "        #training_df['update_age(days)'] = -1\n",
    "        result.append(-1)\n",
    "    else:\n",
    "        if(type(w.updated_date) is list):\n",
    "            update_date=w.updated_date[-1]\n",
    "        else:\n",
    "            update_date=w.updated_date\n",
    "        if(type(update_date) is datetime.datetime):\n",
    "            today_date=datetime.datetime.now()\n",
    "            update_age_in_days=((today_date - update_date).days)\n",
    "            result.append(update_age_in_days)\n",
    "            #training_df['update_age(days)'] = update_age_in_days #### appending updated age in days Appended to the Vector\n",
    "        else:\n",
    "            result.append(-1)\n",
    "            #training_df['update_age(days)'] = -1\n",
    "    \n",
    "    #find the country who is hosting this domain\n",
    "    if(w.country == None):\n",
    "        #training_df['country'] = \"None\"\n",
    "        result.append(\"None\")\n",
    "    else:\n",
    "        #training_df['country'] = w.country\n",
    "        result.append(w.country)\n",
    "     ''' \n",
    "    \n",
    "    #result.append(get_ext(path.path))\n",
    "    result.append(str(label))\n",
    "    return result\n",
    "                  \n",
    "    #Yay! finally done!  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a phishing website lives for a short period of time, we believe that trustworthy domains are regularly paid for several years in advance. But whois server takes few requests per day. So I commented out for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df)):\n",
    "    features = getFeatures(df[\"URL\"].loc[i], df[\"Lable\"].loc[i])    \n",
    "    featureSet.loc[i] = features      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featureSet.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import pickle as pkl\n",
    "from __future__ import division"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets visualize the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " URL length Distributions of both Malicious as well as Benign URLs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style=\"darkgrid\")\n",
    "sns.distplot(featureSet[featureSet['label']=='0']['len of url'],color='green',label='Benign URLs')\n",
    "sns.distplot(featureSet[featureSet['label']=='1']['len of url'],color='red',label='Phishing URLs')\n",
    "sns.plt.title('Url Length Distribution')\n",
    "plt.legend(loc='upper right')\n",
    "plt.xlabel('Length of URL')\n",
    "\n",
    "sns.plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of Dots Distributions of both Malicious as well as Benign URLs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=featureSet[featureSet['label']=='0']['no of dots']\n",
    "y=featureSet[featureSet['label']=='1']['no of dots']\n",
    "plt.hist(x,bins=8, alpha=0.9, label='Benign URLs',color='blue')\n",
    "#sns.distplot(x,bins=8,color='blue',label='Benign URLs')\n",
    "plt.hist(y,bins=10, alpha=0.6, label='Malicious URLs',color='red')\n",
    "#sns.distplot(y,bins=8,color='red',label='Malicious URLs')\n",
    "plt.legend(loc='upper right')\n",
    "plt.xlabel('Number of Dots')\n",
    "plt.title('Distribution of Number of Dots in URL')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Domain length Distributions of both Malicious as well as Benign URLs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style=\"darkgrid\")\n",
    "sns.distplot(featureSet[featureSet['label']=='0']['len of domain'],color='blue',label='Benign URLs')\n",
    "sns.distplot(featureSet[featureSet['label']=='1']['len of domain'],color='red',label='Malicious URLs')\n",
    "sns.plt.title('Domain Length Distribution')\n",
    "plt.legend(loc='upper right')\n",
    "plt.xlabel('Length of Domain/Host')\n",
    "sns.plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "sns.set(style=\"whitegrid\")\n",
    "sns.distplot(featureSet[featureSet['label']==0]['create_age(months)'],color='green',label='Benign URLs')\n",
    "sns.distplot(featureSet[featureSet['label']==1]['create_age(months)'],color='red',label='Malicious URLs')\n",
    "sns.plt.title('Creation Age Distribution')\n",
    "plt.legend(loc='upper right')\n",
    "plt.xlabel('Age of Domain (Months)')\n",
    "sns.plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I can query minimal URL's per day using whois to get domain information. Waiting to get complete feature set, hence commented out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.ensemble as ek\n",
    "from sklearn import cross_validation, tree, linear_model\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn import preprocessing\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import LogisticRegression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's just see the number of Benign and Phishin/Malicious emails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featureSet.groupby(featureSet['label']).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separate label and feature set. It would have been nice if I had domain features too. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = featureSet.drop(['url','label'],axis=1).values\n",
    "y = featureSet['label'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time for Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = { \"DecisionTree\":tree.DecisionTreeClassifier(max_depth=10),\n",
    "         \"RandomForest\":ek.RandomForestClassifier(n_estimators=50),\n",
    "         \"Adaboost\":ek.AdaBoostClassifier(n_estimators=50),\n",
    "         \"GradientBoosting\":ek.GradientBoostingClassifier(n_estimators=50),\n",
    "         \"GNB\":GaussianNB(),\n",
    "         \"LogisticRegression\":LogisticRegression()   \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = cross_validation.train_test_split(X, y ,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "for algo in model:\n",
    "    clf = model[algo]\n",
    "    clf.fit(X_train,y_train)\n",
    "    score = clf.score(X_test,y_test)\n",
    "    print (\"%s : %s \" %(algo, score))\n",
    "    results[algo] = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "winner = max(results, key=results.get)\n",
    "print(winner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = model[winner]\n",
    "res = clf.predict(X)\n",
    "mt = confusion_matrix(y, res)\n",
    "print(\"False positive rate : %f %%\" % ((mt[0][1] / float(sum(mt[0])))*100))\n",
    "print('False negative rate : %f %%' % ( (mt[1][0] / float(sum(mt[1]))*100)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing\n",
    "\n",
    "Let's test' some of the malicious URL's listed in Trend Micro's website. http://apac.trendmicro.com/apac/security-intelligence/current-threat-activity/malicious-top-ten/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame(columns=('url','no of dots','presence of hyphen','len of url','presence of at',\\\n",
    "'presence of double slash','no of subdir','no of subdomain','len of domain','no of queries','is IP','presence of Suspicious_TLD',\\\n",
    "'presence of suspicious domain','label'))\n",
    "\n",
    "results = getFeatures('trafficconverter.biz:80/4vir/antispyware/loadadv.exe', '1')\n",
    "result.loc[0] = results\n",
    "result = result.drop(['url','label'],axis=1).values\n",
    "print(clf.predict(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Success! One more time :) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame(columns=('url','no of dots','presence of hyphen','len of url','presence of at',\\\n",
    "'presence of double slash','no of subdir','no of subdomain','len of domain','no of queries','is IP','presence of Suspicious_TLD',\\\n",
    "'presence of suspicious domain','label'))\n",
    "\n",
    "results = getFeatures('am10.ru:80/code.php', '1')\n",
    "result.loc[0] = results\n",
    "result = result.drop(['url','label'],axis=1).values\n",
    "print(clf.predict(result))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
